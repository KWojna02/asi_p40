{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc68befe-d25e-419c-8ce4-a46f761c9cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision kagglehub\n",
    "!pip install -q pytorch-lightning torchmetrics \"numpy<2.0\"\n",
    "!pip install -q pandas matplotlib seaborn\n",
    "!pip install -q grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc219cf-8fcf-440b-aec7-111e645c5362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import kagglehub\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a822cd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trening: /teamspace/studios/this_studio/.cache/kagglehub/datasets/jutrera/stanford-car-dataset-by-classes-folder/versions/2/car_data/car_data/train\n",
      "Test:    /teamspace/studios/this_studio/.cache/kagglehub/datasets/jutrera/stanford-car-dataset-by-classes-folder/versions/2/car_data/car_data/test\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_WORKERS = 4\n",
    "SEED = 1234\n",
    "\n",
    "CHECKPOINT_BEST = \"best_model.ckpt\"\n",
    "CLASSES_FILE = \"classes.json\"\n",
    "REPORT_FILE = \"raport_aut.csv\"\n",
    "PREDICTIONS_FILE = \"wyniki_efficientnet.csv\"\n",
    "\n",
    "pl.seed_everything(SEED, workers=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PIN_MEMORY = DEVICE.type == \"cuda\"\n",
    "\n",
    "def find_train_test_dirs(base_dir: str):\n",
    "    for root, dirs, _files in os.walk(base_dir):\n",
    "        if \"train\" in dirs and \"test\" in dirs:\n",
    "            candidate_train = os.path.join(root, \"train\")\n",
    "            candidate_test = os.path.join(root, \"test\")\n",
    "            has_class_dirs = any(\n",
    "                os.path.isdir(os.path.join(candidate_train, d))\n",
    "                for d in os.listdir(candidate_train)\n",
    "            )\n",
    "            if has_class_dirs:\n",
    "                return candidate_train, candidate_test\n",
    "    return None, None\n",
    "\n",
    "def dataloader_kwargs():\n",
    "    kwargs = {\"num_workers\": NUM_WORKERS, \"pin_memory\": PIN_MEMORY}\n",
    "    if NUM_WORKERS and NUM_WORKERS > 0:\n",
    "        kwargs[\"persistent_workers\"] = True\n",
    "    return kwargs\n",
    "\n",
    "def make_loader(dataset, *, shuffle: bool):\n",
    "    return DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=shuffle, **dataloader_kwargs())\n",
    "\n",
    "def make_transforms(mode: str):\n",
    "    mode = mode.lower()\n",
    "    if mode == \"train\":\n",
    "        return transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((256, 256)),\n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ColorJitter(0.2, 0.2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "    if mode in {\"val\", \"test\", \"eval\"}:\n",
    "        return transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "    raise ValueError(f\"Nieznany tryb transformacji: {mode}\")\n",
    "\n",
    "def load_eval_model(checkpoint_path: str, *, num_classes: int):\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Brak checkpointu: {checkpoint_path}\")\n",
    "    model = CarClassifier.load_from_checkpoint(\n",
    "        checkpoint_path,\n",
    "        num_classes=num_classes,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weights=None,\n",
    "        trainable_blocks=0,\n",
    "    )\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    model.freeze()\n",
    "    return model\n",
    "\n",
    "BASE_DIR = kagglehub.dataset_download(\"jutrera/stanford-car-dataset-by-classes-folder\")\n",
    "train_dir, test_dir = find_train_test_dirs(BASE_DIR)\n",
    "if not train_dir:\n",
    "    raise FileNotFoundError(\"Nie znaleziono folderów train/test w dataset.\")\n",
    "\n",
    "print(f\"Trening: {train_dir}\")\n",
    "print(f\"Test:    {test_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "313ba582",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        learning_rate: float = 1e-3,\n",
    "        weights: str | None = \"DEFAULT\",\n",
    "        trainable_blocks: int = 3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        self.model = models.efficientnet_v2_s(weights=weights)\n",
    "\n",
    "        if trainable_blocks is not None:\n",
    "            for param in self.model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "            if trainable_blocks > 0:\n",
    "                for param in self.model.features[-trainable_blocks:].parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        in_features = self.model.classifier[1].in_features\n",
    "        self.model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, _batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.train_acc(torch.argmax(logits, dim=1), y)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_acc\", self.train_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, _batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.val_acc(torch.argmax(logits, dim=1), y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.val_acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        params = [{\"params\": self.model.classifier.parameters(), \"lr\": self.lr}]\n",
    "        if getattr(self.hparams, \"trainable_blocks\", 0) and self.hparams.trainable_blocks > 0:\n",
    "            params.insert(\n",
    "                0,\n",
    "                {\n",
    "                    \"params\": self.model.features[-self.hparams.trainable_blocks :].parameters(),\n",
    "                    \"lr\": self.lr * 0.1,\n",
    "                },\n",
    "            )\n",
    "        optimizer = optim.Adam(params)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=\"min\", factor=0.1, patience=2\n",
    "        )\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = make_transforms(\"train\")\n",
    "eval_tf = make_transforms(\"eval\")\n",
    "\n",
    "train_ds = datasets.ImageFolder(train_dir, transform=train_tf)\n",
    "val_ds = datasets.ImageFolder(test_dir, transform=eval_tf)\n",
    "\n",
    "train_loader = make_loader(train_ds, shuffle=True)\n",
    "val_loader = make_loader(val_ds, shuffle=False)\n",
    "\n",
    "class_names = train_ds.classes\n",
    "with open(\"classes.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(class_names, f, ensure_ascii=False)\n",
    "\n",
    "print(f\"Liczba klas: {len(class_names)}\")\n",
    "print(f\"Train: {len(train_ds)} zdjęć\")\n",
    "print(f\"Val:   {len(val_ds)} zdjęć\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cebd376",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start treningu...\")\n",
    "\n",
    "csv_logger = pl.loggers.CSVLogger(save_dir=\"logs\", name=\"efficientnet_experiment\")\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=\".\",\n",
    "    filename=\"best_model\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_acc\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    logger=csv_logger,\n",
    "    enable_progress_bar=True,\n",
    ")\n",
    "\n",
    "model = CarClassifier(num_classes=len(class_names), learning_rate=LEARNING_RATE)\n",
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "print(f\"Trening zakończony. Najlepszy checkpoint: {checkpoint_callback.best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c2b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_path = f\"{csv_logger.log_dir}/metrics.csv\"\n",
    "if not os.path.exists(metrics_path):\n",
    "    print(\"Nie znaleziono metrics.csv (brak logów).\")\n",
    "else:\n",
    "    metrics = pd.read_csv(metrics_path)\n",
    "    epoch_metrics = metrics.groupby(\"epoch\").mean(numeric_only=True)\n",
    "\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    axes[0].plot(epoch_metrics.index, epoch_metrics[\"train_loss\"], marker=\"o\", label=\"Train\")\n",
    "    axes[0].plot(epoch_metrics.index, epoch_metrics[\"val_loss\"], marker=\"o\", label=\"Val\")\n",
    "    axes[0].set_title(\"Loss\")\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(epoch_metrics.index, epoch_metrics[\"train_acc\"], marker=\"o\", label=\"Train\")\n",
    "    axes[1].plot(epoch_metrics.index, epoch_metrics[\"val_acc\"], marker=\"o\", label=\"Val\")\n",
    "    axes[1].set_title(\"Accuracy\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"Accuracy\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"training_curves.png\", dpi=150)\n",
    "    plt.show()\n",
    "    print(\"Zapisano: training_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b36774-479e-4412-b224-fc6170065450",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = checkpoint_callback.best_model_path or CHECKPOINT_BEST\n",
    "model = load_eval_model(checkpoint_path, num_classes=len(class_names))\n",
    "\n",
    "test_ds = datasets.ImageFolder(test_dir, transform=eval_tf)\n",
    "loader = make_loader(test_ds, shuffle=False)\n",
    "\n",
    "file_paths = [s[0] for s in test_ds.samples]\n",
    "rows = []\n",
    "\n",
    "print(f\"Analiza {len(test_ds)} zdjęć (EfficientNet)...\")\n",
    "for batch_idx, (inputs, labels) in enumerate(tqdm(loader, desc=\"Test\")):\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    preds = model(inputs)\n",
    "    probs = torch.softmax(preds, dim=1)\n",
    "    scores, pred_ids = torch.max(probs, dim=1)\n",
    "\n",
    "    start_i = batch_idx * loader.batch_size\n",
    "    for i in range(len(inputs)):\n",
    "        idx_global = start_i + i\n",
    "        if idx_global >= len(file_paths):\n",
    "            break\n",
    "\n",
    "        path = file_paths[idx_global]\n",
    "        filename = os.path.basename(path)\n",
    "        true_name = class_names[labels[i].item()]\n",
    "        pred_name = class_names[pred_ids[i].item()]\n",
    "        score_pct = float(scores[i].item()) * 100\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"Plik\": filename,\n",
    "                \"Prawdziwe Auto\": true_name,\n",
    "                \"Wykryte Auto\": pred_name,\n",
    "                \"Pewnosc Modelu\": f\"{score_pct:.2f}%\",\n",
    "                \"Czy Trafil\": \"TAK\" if true_name == pred_name else \"NIE\",\n",
    "            }\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "acc = (df[\"Czy Trafil\"] == \"TAK\").mean() * 100\n",
    "\n",
    "print(f\"Skuteczność: {acc:.2f}%\")\n",
    "df.to_csv(PREDICTIONS_FILE, index=False, encoding=\"utf-8\")\n",
    "df.drop(columns=[\"Plik\"]).to_csv(REPORT_FILE, index=False, encoding=\"utf-8\")\n",
    "print(f\"Zapisano: {PREDICTIONS_FILE}\")\n",
    "print(f\"Zapisano: {REPORT_FILE}\")\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f870be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "COMPARISON_OUTPUT_FILE = \"porownanie_modeli_klasy.csv\"\n",
    "\n",
    "def generate_report(csv_path: str, model_name: str):\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Brak pliku: {csv_path}\")\n",
    "        return None\n",
    "\n",
    "    df_local = pd.read_csv(csv_path)\n",
    "    report = df_local.groupby(\"Prawdziwe Auto\").agg(\n",
    "        photos_count=(\"Plik\", \"count\"),\n",
    "        guesses=(\"Czy Trafil\", lambda x: (x == \"TAK\").sum()),\n",
    ")\n",
    "    report[\"accuracy\"] = report[\"guesses\"] / report[\"photos_count\"] * 100\n",
    "    report = report.sort_values(by=\"accuracy\", ascending=True)\n",
    "    print(f\"\\n{model_name}: (najgorsze klasy na górze)\")\n",
    "    print(report[[\"photos_count\", \"accuracy\"]].head(20))\n",
    "    return report[[\"accuracy\"]].rename(columns={\"accuracy\": model_name})\n",
    "\n",
    "eff_stats = generate_report(\"wyniki_efficientnet.csv\", \"EfficientNet\")\n",
    "conv_stats = generate_report(\"wyniki_convnext.csv\", \"ConvNeXt\")\n",
    "\n",
    "if eff_stats is not None and conv_stats is not None:\n",
    "    comparison = pd.concat([eff_stats, conv_stats], axis=1)\n",
    "    comparison[\"Różnica\"] = comparison[\"ConvNeXt\"] - comparison[\"EfficientNet\"]\n",
    "    comparison = comparison.sort_values(by=\"Różnica\", ascending=False)\n",
    "    print(\"\\nTop różnic (ConvNeXt - EfficientNet):\")\n",
    "    print(comparison.head(30))\n",
    "    comparison.to_csv(COMPARISON_OUTPUT_FILE, encoding=\"utf-8\")\n",
    "    print(f\"\\nZapisano: {COMPARISON_OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dfa842",
   "metadata": {},
   "outputs": [],
   "source": [
    "EFF_CHECKPOINT = \"best_model.ckpt\"\n",
    "CONV_CHECKPOINT = \"best_convnext.ckpt\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CarClassifierEffNetEval(pl.LightningModule):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.model = models.efficientnet_v2_s(weights=None)\n",
    "        in_features = self.model.classifier[1].in_features\n",
    "        self.model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class CarClassifierConvNextEval(pl.LightningModule):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.model = models.convnext_tiny(weights=None)\n",
    "        in_features = self.model.classifier[2].in_features\n",
    "        self.model.classifier[2] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model_eff = None\n",
    "if os.path.exists(EFF_CHECKPOINT):\n",
    "    model_eff = CarClassifierEffNetEval.load_from_checkpoint(EFF_CHECKPOINT, num_classes=len(class_names))\n",
    "    model_eff.eval().to(device)\n",
    "else:\n",
    "    print(f\"Brak checkpointu EfficientNet: {EFF_CHECKPOINT}\")\n",
    "\n",
    "model_conv = None\n",
    "if os.path.exists(CONV_CHECKPOINT):\n",
    "    model_conv = CarClassifierConvNextEval.load_from_checkpoint(CONV_CHECKPOINT, num_classes=len(class_names))\n",
    "    model_conv.eval().to(device)\n",
    "else:\n",
    "    print(f\"Brak checkpointu ConvNeXt: {CONV_CHECKPOINT}\")\n",
    "\n",
    "def visualize_comparison(image_path: str):\n",
    "    img_pil = Image.open(image_path).convert(\"RGB\").resize((224, 224))\n",
    "    rgb_img = np.float32(img_pil) / 255.0\n",
    "    input_tensor = preprocess_image(\n",
    "        rgb_img,\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ).to(device)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    axs[0].imshow(img_pil)\n",
    "    axs[0].set_title(os.path.basename(image_path))\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    if model_eff is not None:\n",
    "        cam_eff = GradCAM(model=model_eff, target_layers=[model_eff.model.features[-1]])\n",
    "        grayscale_cam_eff = cam_eff(input_tensor=input_tensor, targets=None)\n",
    "        vis_eff = show_cam_on_image(rgb_img, grayscale_cam_eff[0, :], use_rgb=True)\n",
    "\n",
    "        preds_eff = model_eff(input_tensor)\n",
    "        idx_eff = int(torch.argmax(preds_eff, dim=1).item())\n",
    "        conf_eff = float(torch.softmax(preds_eff, dim=1)[0, idx_eff].item())\n",
    "\n",
    "        axs[1].imshow(vis_eff)\n",
    "        axs[1].set_title(f\"EfficientNet: {class_names[idx_eff]} ({conf_eff:.1%})\")\n",
    "        axs[1].axis(\"off\")\n",
    "    else:\n",
    "        axs[1].text(0.5, 0.5, \"Brak EfficientNet\", ha=\"center\", va=\"center\")\n",
    "        axs[1].axis(\"off\")\n",
    "\n",
    "    if model_conv is not None:\n",
    "        cam_conv = GradCAM(model=model_conv, target_layers=[model_conv.model.features[-1]])\n",
    "        grayscale_cam_conv = cam_conv(input_tensor=input_tensor, targets=None)\n",
    "        vis_conv = show_cam_on_image(rgb_img, grayscale_cam_conv[0, :], use_rgb=True)\n",
    "\n",
    "        preds_conv = model_conv(input_tensor)\n",
    "        idx_conv = int(torch.argmax(preds_conv, dim=1).item())\n",
    "        conf_conv = float(torch.softmax(preds_conv, dim=1)[0, idx_conv].item())\n",
    "\n",
    "        axs[2].imshow(vis_conv)\n",
    "        axs[2].set_title(f\"ConvNeXt: {class_names[idx_conv]} ({conf_conv:.1%})\")\n",
    "        axs[2].axis(\"off\")\n",
    "    else:\n",
    "        axs[2].text(0.5, 0.5, \"Brak ConvNeXt\", ha=\"center\", va=\"center\")\n",
    "        axs[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "test_images = [p for p, _ in datasets.ImageFolder(test_dir, transform=make_transforms(\"eval\")).samples]\n",
    "sample = random.sample(test_images, k=min(5, len(test_images)))\n",
    "print(f\"Wybrano {len(sample)} obrazów do porównania.\")\n",
    "for img_path in sample:\n",
    "    visualize_comparison(img_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
