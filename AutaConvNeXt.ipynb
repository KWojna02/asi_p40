{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc68befe-d25e-419c-8ce4-a46f761c9cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision kagglehub\n",
    "!pip install -q pytorch-lightning torchmetrics \"numpy<2.0\"\n",
    "!pip install -q pandas matplotlib seaborn\n",
    "!pip install -q grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97121b98-7eeb-4c1f-b339-72efb7519e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import kagglehub\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc219cf-8fcf-440b-aec7-111e645c5362",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_WORKERS = 2\n",
    "SEED = 1234\n",
    "\n",
    "CHECKPOINT_BEST = \"best_convnext.ckpt\"\n",
    "CLASSES_FILE = \"classes.json\"\n",
    "OUTPUT_FILE = \"wyniki_convnext.csv\"\n",
    "\n",
    "pl.seed_everything(SEED, workers=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PIN_MEMORY = DEVICE.type == \"cuda\"\n",
    "\n",
    "def find_train_test_dirs(base_dir: str):\n",
    "    for root, dirs, _files in os.walk(base_dir):\n",
    "        if \"train\" in dirs and \"test\" in dirs:\n",
    "            candidate_train = os.path.join(root, \"train\")\n",
    "            candidate_test = os.path.join(root, \"test\")\n",
    "            has_class_dirs = any(\n",
    "                os.path.isdir(os.path.join(candidate_train, d))\n",
    "                for d in os.listdir(candidate_train)\n",
    "            )\n",
    "            if has_class_dirs:\n",
    "                return candidate_train, candidate_test\n",
    "    return None, None\n",
    "\n",
    "def dataloader_kwargs():\n",
    "    kwargs = {\"num_workers\": NUM_WORKERS, \"pin_memory\": PIN_MEMORY}\n",
    "    if NUM_WORKERS and NUM_WORKERS > 0:\n",
    "        kwargs[\"persistent_workers\"] = True\n",
    "    return kwargs\n",
    "\n",
    "def make_loader(dataset, *, shuffle: bool):\n",
    "    return DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=shuffle, **dataloader_kwargs())\n",
    "\n",
    "def make_transforms(mode: str):\n",
    "    mode = mode.lower()\n",
    "    if mode == \"train\":\n",
    "        return transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((256, 256)),\n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ColorJitter(0.2, 0.2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "    if mode in {\"val\", \"test\", \"eval\"}:\n",
    "        return transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "    raise ValueError(f\"Nieznany tryb transformacji: {mode}\")\n",
    "\n",
    "def load_eval_model(checkpoint_path: str, *, num_classes: int):\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Brak checkpointu: {checkpoint_path}\")\n",
    "    model = CarClassifierConvNext.load_from_checkpoint(\n",
    "        checkpoint_path,\n",
    "        num_classes=num_classes,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "    )\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    model.freeze()\n",
    "    return model\n",
    "\n",
    "try:\n",
    "    BASE_DIR = kagglehub.dataset_download(\"jutrera/stanford-car-dataset-by-classes-folder\")\n",
    "except Exception:\n",
    "    BASE_DIR = \".\"\n",
    "\n",
    "train_dir, test_dir = find_train_test_dirs(BASE_DIR)\n",
    "if not train_dir:\n",
    "    raise FileNotFoundError(\"Nie znaleziono danych. Sprawdź, czy dataset jest podpięty.\")\n",
    "\n",
    "print(f\"Trening: {train_dir}\")\n",
    "print(f\"Test:    {test_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "412cce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarClassifierConvNext(pl.LightningModule):\n",
    "    def __init__(self, num_classes: int, learning_rate: float = 1e-4):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        self.model = models.convnext_tiny(weights=\"DEFAULT\")\n",
    "\n",
    "        for param in self.model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.model.features[-2:].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        in_features = self.model.classifier[2].in_features\n",
    "        self.model.classifier[2] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, _batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.train_acc(torch.argmax(logits, dim=1), y)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_acc\", self.train_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, _batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.val_acc(torch.argmax(logits, dim=1), y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.val_acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(\n",
    "            [\n",
    "                {\"params\": self.model.features[-2:].parameters(), \"lr\": self.lr * 0.1},\n",
    "                {\"params\": self.model.classifier.parameters(), \"lr\": self.lr},\n",
    "            ],\n",
    "            weight_decay=1e-4,\n",
    ")\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=\"min\", factor=0.1, patience=2\n",
    "        )\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41876837",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = make_transforms(\"train\")\n",
    "eval_tf = make_transforms(\"eval\")\n",
    "\n",
    "train_ds = datasets.ImageFolder(train_dir, transform=train_tf)\n",
    "val_ds = datasets.ImageFolder(test_dir, transform=eval_tf)\n",
    "\n",
    "train_loader = make_loader(train_ds, shuffle=True)\n",
    "val_loader = make_loader(val_ds, shuffle=False)\n",
    "\n",
    "class_names = train_ds.classes\n",
    "with open(\"classes.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(class_names, f, ensure_ascii=False)\n",
    "\n",
    "print(f\"Liczba klas: {len(class_names)}\")\n",
    "print(f\"Train: {len(train_ds)} zdjęć\")\n",
    "print(f\"Val:   {len(val_ds)} zdjęć\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start treningu ConvNeXt...\")\n",
    "\n",
    "csv_logger = pl.loggers.CSVLogger(save_dir=\"logs\", name=\"convnext_experiment\")\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=\".\",\n",
    "    filename=\"best_convnext\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_acc\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    logger=csv_logger,\n",
    "    enable_progress_bar=True,\n",
    ")\n",
    "\n",
    "model = CarClassifierConvNext(num_classes=len(class_names), learning_rate=LEARNING_RATE)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "print(f\"Trening zakończony. Najlepszy checkpoint: {checkpoint_callback.best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398c859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_path = f\"{csv_logger.log_dir}/metrics.csv\"\n",
    "if not os.path.exists(metrics_path):\n",
    "    print(\"Nie znaleziono metrics.csv (brak logów).\")\n",
    "else:\n",
    "    metrics = pd.read_csv(metrics_path)\n",
    "    epoch_metrics = metrics.groupby(\"epoch\").mean(numeric_only=True)\n",
    "\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    axes[0].plot(epoch_metrics.index, epoch_metrics[\"train_loss\"], marker=\"o\", label=\"Train\")\n",
    "    axes[0].plot(epoch_metrics.index, epoch_metrics[\"val_loss\"], marker=\"o\", label=\"Val\")\n",
    "    axes[0].set_title(\"Loss\")\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(epoch_metrics.index, epoch_metrics[\"train_acc\"], marker=\"o\", label=\"Train\")\n",
    "    axes[1].plot(epoch_metrics.index, epoch_metrics[\"val_acc\"], marker=\"o\", label=\"Val\")\n",
    "    axes[1].set_title(\"Accuracy\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"Accuracy\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"convnext_training_curves.png\", dpi=150)\n",
    "    plt.show()\n",
    "    print(\"Zapisano: convnext_training_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b3fcd-4196-442a-8ff8-e47ce4d9ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = checkpoint_callback.best_model_path or CHECKPOINT_BEST\n",
    "model = load_eval_model(checkpoint_path, num_classes=len(class_names))\n",
    "\n",
    "test_ds = datasets.ImageFolder(test_dir, transform=eval_tf)\n",
    "loader = make_loader(test_ds, shuffle=False)\n",
    "\n",
    "file_paths = [s[0] for s in test_ds.samples]\n",
    "rows = []\n",
    "\n",
    "print(f\"Analiza {len(test_ds)} zdjęć (ConvNeXt)...\")\n",
    "for batch_idx, (inputs, labels) in enumerate(tqdm(loader, desc=\"Test\")):\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    preds = model(inputs)\n",
    "    probs = torch.softmax(preds, dim=1)\n",
    "    scores, pred_ids = torch.max(probs, dim=1)\n",
    "\n",
    "    start_i = batch_idx * loader.batch_size\n",
    "    for i in range(len(inputs)):\n",
    "        idx_global = start_i + i\n",
    "        if idx_global >= len(file_paths):\n",
    "            break\n",
    "\n",
    "        path = file_paths[idx_global]\n",
    "        filename = os.path.basename(path)\n",
    "        true_name = class_names[labels[i].item()]\n",
    "        pred_name = class_names[pred_ids[i].item()]\n",
    "        score_pct = float(scores[i].item()) * 100\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"Plik\": filename,\n",
    "                \"Prawdziwe Auto\": true_name,\n",
    "                \"Wykryte Auto\": pred_name,\n",
    "                \"Pewnosc Modelu\": f\"{score_pct:.2f}%\",\n",
    "                \"Czy Trafil\": \"TAK\" if true_name == pred_name else \"NIE\",\n",
    "            }\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "acc = (df[\"Czy Trafil\"] == \"TAK\").mean() * 100\n",
    "\n",
    "print(f\"Skuteczność: {acc:.2f}%\")\n",
    "df.to_csv(OUTPUT_FILE, index=False, encoding=\"utf-8\")\n",
    "print(f\"Zapisano: {OUTPUT_FILE}\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e3d16-ab82-4167-a182-b13fdbbc51dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "COMPARISON_OUTPUT_FILE = 'porownanie_modeli_klasy.csv'\n",
    "\n",
    "def generate_report(csv, model):\n",
    "    print(f\"\\n{'='*20} ANALIZA: {model.upper()} {'='*20}\")\n",
    "    \n",
    "    if not os.path.exists(csv):\n",
    "        print(f\"Brak pliku csv\")\n",
    "        return None\n",
    "\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    report = df.groupby(\"Prawdziwe Auto\").agg(\n",
    "        photos_count=('Plik', 'count'),\n",
    "        guesses=('Czy Trafil', lambda x: (x == 'TAK').sum())\n",
    "    )\n",
    "    \n",
    "    report['accuracy'] = (report['guesses'] / report['photos_count']) * 100    \n",
    "    report = report.sort_values(by='accuracy', ascending=True)    \n",
    "    report_display = report.copy()\n",
    "    report_display['accuracy'] = report_display['accuracy'].apply(lambda x: f\"{x:.1f}%\")\n",
    "    \n",
    "    print(report_display[['photos_count', 'accuracy']])\n",
    "    \n",
    "    output = f\"raport_klas_{model.lower()}.csv\"\n",
    "    report.to_csv(output)\n",
    "    print(f\"\\nZapisano szczegóły w: {output}\")\n",
    "    \n",
    "    return report[['accuracy']] \n",
    "    \n",
    "eff_stats = generate_report(\"wyniki_efficientnet.csv\", \"EfficientNet\")\n",
    "\n",
    "conv_stats = generate_report(\"wyniki_convnext.csv\", \"ConvNeXt\")\n",
    "\n",
    "if eff_stats is not None and conv_stats is not None:    \n",
    "    comparison = pd.concat([eff_stats, conv_stats], axis=1)\n",
    "    comparison.columns = ['EffNet Acc', 'ConvNeXt Acc']\n",
    "    \n",
    "    comparison['Różnica'] = comparison['ConvNeXt Acc'] - comparison['EffNet Acc']\n",
    "    \n",
    "    comparison = comparison.sort_values(by='Różnica', ascending=False)\n",
    "    \n",
    "    print(comparison)\n",
    "    \n",
    "    comparison.to_csv(COMPARISON_OUTPUT_FILE)\n",
    "    print(f\"\\nZapisano porównanie w: {COMPARISON_OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713f207e-d451-4577-a008-da71242b05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EFF_CHECKPOINT = \"best_model.ckpt\"\n",
    "CONV_CHECKPOINT = checkpoint_callback.best_model_path or \"best_convnext.ckpt\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CarClassifierEffNet(pl.LightningModule):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.model = models.efficientnet_v2_s(weights=None)\n",
    "        in_features = self.model.classifier[1].in_features\n",
    "        self.model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class CarClassifierConvNextEval(pl.LightningModule):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.model = models.convnext_tiny(weights=None)\n",
    "        in_features = self.model.classifier[2].in_features\n",
    "        self.model.classifier[2] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model_eff = None\n",
    "if os.path.exists(EFF_CHECKPOINT):\n",
    "    model_eff = CarClassifierEffNet.load_from_checkpoint(EFF_CHECKPOINT, num_classes=len(class_names))\n",
    "    model_eff.eval().to(device)\n",
    "else:\n",
    "    print(f\"Brak checkpointu EfficientNet: {EFF_CHECKPOINT}\")\n",
    "\n",
    "model_conv = None\n",
    "if os.path.exists(CONV_CHECKPOINT):\n",
    "    model_conv = CarClassifierConvNextEval.load_from_checkpoint(CONV_CHECKPOINT, num_classes=len(class_names))\n",
    "    model_conv.eval().to(device)\n",
    "else:\n",
    "    print(f\"Brak checkpointu ConvNeXt: {CONV_CHECKPOINT}\")\n",
    "\n",
    "def visualize_comparison(image_path: str):\n",
    "    img_pil = Image.open(image_path).convert(\"RGB\").resize((224, 224))\n",
    "    rgb_img = np.float32(img_pil) / 255.0\n",
    "    input_tensor = preprocess_image(\n",
    "        rgb_img,\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ).to(device)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    axs[0].imshow(img_pil)\n",
    "    axs[0].set_title(os.path.basename(image_path))\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    if model_eff is not None:\n",
    "        cam_eff = GradCAM(model=model_eff, target_layers=[model_eff.model.features[-1]])\n",
    "        grayscale_cam_eff = cam_eff(input_tensor=input_tensor, targets=None)\n",
    "        vis_eff = show_cam_on_image(rgb_img, grayscale_cam_eff[0, :], use_rgb=True)\n",
    "\n",
    "        preds_eff = model_eff(input_tensor)\n",
    "        idx_eff = int(torch.argmax(preds_eff, dim=1).item())\n",
    "        conf_eff = float(torch.softmax(preds_eff, dim=1)[0, idx_eff].item())\n",
    "\n",
    "        axs[1].imshow(vis_eff)\n",
    "        axs[1].set_title(f\"EfficientNet: {class_names[idx_eff]} ({conf_eff:.1%})\")\n",
    "        axs[1].axis(\"off\")\n",
    "    else:\n",
    "        axs[1].text(0.5, 0.5, \"Brak EfficientNet\", ha=\"center\", va=\"center\")\n",
    "        axs[1].axis(\"off\")\n",
    "\n",
    "    if model_conv is not None:\n",
    "        cam_conv = GradCAM(model=model_conv, target_layers=[model_conv.model.features[-1]])\n",
    "        grayscale_cam_conv = cam_conv(input_tensor=input_tensor, targets=None)\n",
    "        vis_conv = show_cam_on_image(rgb_img, grayscale_cam_conv[0, :], use_rgb=True)\n",
    "\n",
    "        preds_conv = model_conv(input_tensor)\n",
    "        idx_conv = int(torch.argmax(preds_conv, dim=1).item())\n",
    "        conf_conv = float(torch.softmax(preds_conv, dim=1)[0, idx_conv].item())\n",
    "\n",
    "        axs[2].imshow(vis_conv)\n",
    "        axs[2].set_title(f\"ConvNeXt: {class_names[idx_conv]} ({conf_conv:.1%})\")\n",
    "        axs[2].axis(\"off\")\n",
    "    else:\n",
    "        axs[2].text(0.5, 0.5, \"Brak ConvNeXt\", ha=\"center\", va=\"center\")\n",
    "        axs[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "test_images = [p for p, _ in datasets.ImageFolder(test_dir, transform=val_tf).samples]\n",
    "sample = random.sample(test_images, k=min(5, len(test_images)))\n",
    "print(f\"Wybrano {len(sample)} obrazów do porównania.\")\n",
    "for img_path in sample:\n",
    "    visualize_comparison(img_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
